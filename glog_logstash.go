// Go support for leveled logs, analogous to https://code.google.com/p/google-glog/
//
// Modifications copyright 2013 Ernest Micklei. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package glog

import (
	"bufio"
	"encoding/json"
	"flag"
	"io"
	"os"
	"time"
)

/*
{
   "@source":"test.here.com",
   "@type":"glog",
   "@timestamp":"2013-10-24T09:30:46.947024155+02:00",
   "@fields":{
      "level":"INFO",
      "threadid":400004,
      "file":"file.go",
      "line":10
   },
   "@message":"hello"
}
*/

// logstashAdapter is a glogJSON that decodes glog data and encodes it into JSON.
var logstashAdapter glogJSON

// Set the io.Writer to write JSON. This is required if -logstash=true
// Logstash message details are buffered until the message is complete.
// Logstash messages are written asynchronously to the given writer.
func SetLogstashWriter(writer io.Writer) {
	logstashAdapter.asyncWriter = newAsyncWriter(writer, logstashAdapter.asyncBufferCapacity)
	bufferedWriter := bufio.NewWriter(logstashAdapter.asyncWriter)
	logstashAdapter.writer = bufferedWriter
	logstashAdapter.encoder = json.NewEncoder(bufferedWriter)
}

func init() {
	flag.BoolVar(&logstashAdapter.toLogstash, "logstash", false, "log also in JSON using the Logstash writer")
	flag.IntVar(&logstashAdapter.asyncBufferCapacity, "logstash.capacity", 1000, "how many messages can be queued for async writes")
	// Write to Stderr until SetLogstashWriter is called so we do not loose events.
	SetLogstashWriter(os.Stderr)
}

// glogJSON can decode the data generated by glog and encode it in logstash json format.
// https://gist.github.com/jordansissel/2996677
// implements io.Writer
type glogJSON struct {
	toLogstash          bool          // The -logstash flag.
	asyncBufferCapacity int           // The -logstash.capacity flag.
	asyncWriter         *asyncWriter  // reference needed for Flush.
	writer              *bufio.Writer // destination of log messages.
	encoder             *json.Encoder // used to encode string parameters.
}

// Write decodes the data and writes a logstash json event
func (d glogJSON) WriteWithStack(data []byte, stack []byte) {
	if len(data) == 0 {
		return
	}
	d.openEvent()
	// peek for normal logline
	sev := data[0]
	switch sev {
	case 73, 87, 69, 70: // IWEF
		d.iwef(sev, data, stack)
	default:
		d.message(string(data))
	}
	d.closeHash()
	// flush the complete message
	d.writer.Flush()
}

// openEvent writes the "header" part of the JSON message.
func (d glogJSON) openEvent() {
	io.WriteString(d.writer, `{"@source":`)
	d.encoder.Encode(host) // uses glog package var
	io.WriteString(d.writer, `,"@type":"glog"`)
	io.WriteString(d.writer, `,"@timestamp":`)
	// ignore time information given, take new snapshot
	d.encoder.Encode(timeNow()) // use testable function stored in var
}

// closeAll writes the closing brackets for the main and fields hash.
func (d glogJSON) closeHash() {
	io.WriteString(d.writer, "}\n")
}

// message adds a JSON field with the JSON encoded message.
func (d glogJSON) message(msg string) {
	io.WriteString(d.writer, `,"@message":`)
	d.encoder.Encode(msg)
}

// stack adds a JSON field with the JSON encoded stack trace of all goroutines.
func (d glogJSON) stacktrace(stacktrace []byte) {
	io.WriteString(d.writer, `,"stack":`)
	d.encoder.Encode(string(stacktrace))
}

// iwef decodes a glog data packet and write the JSON representation.
// [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
func (d glogJSON) iwef(sev byte, data []byte, trace []byte) {
	io.WriteString(d.writer, `,"@fields":{"level":"`)
	switch sev {
	case 73:
		io.WriteString(d.writer, "INFO")
	case 87:
		io.WriteString(d.writer, "ERROR")
	case 69:
		io.WriteString(d.writer, "WARNING")
	case 70:
		io.WriteString(d.writer, "FATAL")
	}
	r := &iwefreader{data, 22} // past last u
	io.WriteString(d.writer, `","threadid":`)
	io.WriteString(d.writer, r.stringUpTo(32)) // space
	r.skip()                                   // space
	io.WriteString(d.writer, `,"file":"`)
	io.WriteString(d.writer, r.stringUpTo(58)) // :
	r.skip()                                   // :
	io.WriteString(d.writer, `","line":`)
	io.WriteString(d.writer, r.stringUpTo(93)) // ]
	// ]
	r.skip()
	// space
	r.skip()
	if trace != nil && len(trace) > 0 {
		d.stacktrace(trace)
	}
	// fields
	d.closeHash()
	d.message(r.stringUpToLineEnd())
}

// flush waits until all pending messages are written by the asyncWriter.
func (d glogJSON) flush() {
	if d.asyncWriter != nil { // happens if SetLogstashWriter is not called.
		d.asyncWriter.flush()
	}
}

// iwefreader is a small helper object to parse a glog IWEF entry
type iwefreader struct {
	data     []byte
	position int // read offset in data
}

// skip advances the position in data
func (i *iwefreader) skip() {
	i.position++
}

// stringUpToLineEnd returns the string part from the data up to not-including the line end.
func (i iwefreader) stringUpToLineEnd() string {
	return string(i.data[i.position : len(i.data)-1]) // without the line delimiter
}

// stringUpTo returns the string part from the data up to not-including a delimiter.
func (i *iwefreader) stringUpTo(delim byte) string {
	start := i.position
	for i.data[i.position] != delim {
		i.position++
	}
	return string(i.data[start:i.position])
}

// asyncWriter writes []byte in a separate goroutine.
type asyncWriter struct {
	dataChannel chan []byte
	writer      io.Writer
}

// Write is for implementing io.Writer
func (a asyncWriter) Write(data []byte) (n int, err error) {
	a.dataChannel <- data
	return len(data), nil
}

// flush drains the dataChannel
func (a asyncWriter) flush() {
	for len(a.dataChannel) > 0 {
		time.Sleep(time.Duration(10) * time.Millisecond)
	}
}

// newAsyncWriter returns a new asyncWriter
func newAsyncWriter(writer io.Writer, bufferCapacity int) *asyncWriter {
	aw := &asyncWriter{make(chan []byte, bufferCapacity), writer}
	go func() {
		for {
			aw.writer.Write(<-aw.dataChannel)
		}
	}()
	return aw
}
